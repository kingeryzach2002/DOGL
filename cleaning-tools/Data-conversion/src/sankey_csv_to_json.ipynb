{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 6): 0, (0, 7): 1, (0, 8): 2, (0, 9): 3, (0, 10): 4, (0, 11): 5, (1, 6): 6, (1, 7): 7, (1, 8): 8, (1, 9): 9, (1, 10): 10, (1, 11): 11, (2, 6): 12, (2, 7): 13, (2, 8): 14, (2, 9): 15, (2, 10): 16, (2, 11): 17, (3, 6): 18, (3, 7): 19, (3, 8): 20, (3, 9): 21, (3, 10): 22, (3, 11): 23, (4, 6): 24, (4, 7): 25, (4, 8): 26, (4, 9): 27, (4, 10): 28, (4, 11): 29, (5, 6): 30, (5, 7): 31, (5, 8): 32, (5, 9): 33, (5, 10): 34, (5, 11): 35}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data_path = '/Users/zfrancis/Documents/Personal_Work_Stuff/programs/odsi/DOGL_Repo/DOGL/cleaning-tools/Data-conversion/data/sankey_test_categories.csv'\n",
    "nodes = []\n",
    "links = []\n",
    "\n",
    "# Gets node IDs for categories 1 and 2\n",
    "def get_node_ids(df):\n",
    "    node_ids = {}\n",
    "    next_id = 0\n",
    "    for col_index in [1, 2]:  \n",
    "        categories = get_unique(df, col_index)\n",
    "        for category in categories:\n",
    "            if category not in node_ids:\n",
    "                node_ids[category] = next_id\n",
    "                next_id += 1\n",
    "    return node_ids\n",
    "\n",
    "# What is this code doing?\n",
    "def get_node_strength(category):\n",
    "    for node_list in nodes:\n",
    "        for node in node_list:\n",
    "            if node['name'] == category:\n",
    "                return node['score']\n",
    "    return None\n",
    "\n",
    "def get_unique(df, col_index): #Get the unique values in a column\n",
    "    column = df[df.columns[col_index]]\n",
    "    split_list = column.str.split('; ')\n",
    "    split_list = split_list.explode()\n",
    "    split_unique = split_list.unique()\n",
    "    return split_unique\n",
    "\n",
    "# Function for calculating node scores\n",
    "def calculate_node_scores(df, col_index, node_ids):\n",
    "    categories = get_unique(df, col_index)\n",
    "    scores = {category: 0 for category in categories}\n",
    "    \n",
    "    for _, row in df.iterrows(): #Iterates over each cell in the column\n",
    "        \n",
    "        categories_in_cell = str(row[col_index]).split('; ') #Splits the cell into categories\n",
    "        score_split = 1 / len(categories_in_cell) #Splits the score equal to the number of different categories\n",
    "        for category in categories_in_cell: \n",
    "            if category in scores:\n",
    "                scores[category] += score_split    \n",
    "\n",
    "    total_score = sum(scores.values())\n",
    "    for category in scores:\n",
    "        scores[category] /= total_score #Divides by the total score (number of rows)\n",
    "    \n",
    "    output = [{\"node\": node_ids[category], \"name\": category, \"score\": score} for category, score in scores.items()]\n",
    "    return output #Stores as a list of dicts\n",
    "\n",
    "# Function for calculating link scores\n",
    "def calculate_link_scores(df, node_ids):\n",
    "    # Initialize links\n",
    "    origin_categories = get_unique(df, 1)\n",
    "    target_categories = get_unique(df, 2)\n",
    "    links = []\n",
    "    for origin_category in origin_categories:\n",
    "        for target_category in target_categories:\n",
    "            links.append({\n",
    "                \"source\": node_ids[origin_category], \n",
    "                \"target\": node_ids[target_category], \n",
    "                \"score\": 0\n",
    "            })\n",
    "    \n",
    "    # Mapping dictionary for quick reference of category ID to link index\n",
    "    link_index_map = {(link['source'], link['target']): idx for idx, link in enumerate(links)}\n",
    "    print(link_index_map)\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        origin_categories = set(str(row[1]).split('; '))\n",
    "        target_categories = set(str(row[2]).split('; '))\n",
    "\n",
    "        # Check if there's only one entry in each column\n",
    "        if len(origin_categories) == 1 and len(target_categories) == 1:\n",
    "            origin_id = node_ids[list(origin_categories)[0]]\n",
    "            target_id = node_ids[list(target_categories)[0]]\n",
    "            link_idx = link_index_map[(origin_id, target_id)]\n",
    "            links[link_idx]['score'] += 1 / total_rows\n",
    "        else:\n",
    "            # Distribute score across matrix\n",
    "            total_combinations = len(origin_categories) * len(target_categories)\n",
    "            score_per_combination = 1 / total_combinations / total_rows if total_combinations else 0\n",
    "            for origin_category in origin_categories:\n",
    "                for target_category in target_categories:\n",
    "                    origin_id = node_ids[origin_category]\n",
    "                    target_id = node_ids[target_category]\n",
    "                    link_idx = link_index_map[(origin_id, target_id)]\n",
    "                    links[link_idx]['score'] += score_per_combination\n",
    "\n",
    "    \n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "def category_to_sankey(path, output_path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[(df[df.columns[1]] != 'Not indicated') & (df[df.columns[2]] != 'Not indicated')] \n",
    "    node_ids = get_node_ids(df)\n",
    "\n",
    "    # Calculate node scores for each column\n",
    "    nodes_col1 = calculate_node_scores(df, 1, node_ids)\n",
    "    nodes_col2 = calculate_node_scores(df, 2, node_ids)\n",
    "\n",
    "    # Combine nodes from both columns, avoiding duplicates\n",
    "    combined_nodes = nodes_col1 + [node for node in nodes_col2 if node not in nodes_col1]\n",
    "\n",
    "    # Calculate link scores\n",
    "    links = calculate_link_scores(df, node_ids)\n",
    "\n",
    "    # Combine nodes and links into a single dictionary\n",
    "    sankey_data = {\"nodes\": combined_nodes, \"links\": links}\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f: \n",
    "        json.dump(sankey_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return sankey_data\n",
    "\n",
    "\n",
    "\n",
    "# Set the path for your output JSON file\n",
    "output_json_path = '/Users/zfrancis/Documents/Personal_Work_Stuff/programs/odsi/DOGL_Repo/DOGL/analysis-tools/Sankey-R/data/sankey_data_test.json'\n",
    "\n",
    "# Call the function\n",
    "sankey_data = category_to_sankey(data_path, output_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odsi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
