{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/0hr75ykx133b0bk5k4nf52580000gn/T/ipykernel_62939/352259237.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  partners_list_df['cleaned'] = partners_list_df['cleaned'].str.replace(old_text, new_text)\n",
      "/var/folders/2p/0hr75ykx133b0bk5k4nf52580000gn/T/ipykernel_62939/352259237.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  partners_list_df['cleaned'] = partners_list_df['cleaned'].str.replace(old_text, new_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23    Comoros; Kenya; Madagascar; Mauritius; Mozambi...\n",
      "80                                  National Geographic\n",
      "90    National Oceanic and Atmospheric Administratio...\n",
      "88    International Association of Aquatic and Marin...\n",
      "17    Centre for Documentation, Research and Experim...\n",
      "32    National Oceanic and Atmospheric Administratio...\n",
      "38                                        Not Indicated\n",
      "13    Jeff Ardron, Commonwealth Secretariat, UK; Jon...\n",
      "53    Accenture; Aker ASA; Aker Biomarine; AkerBP; A...\n",
      "87    Indian National Center for Ocean Information S...\n",
      "Name: cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "path = '/Users/zfrancis/Documents/Personal_Work_Stuff/programs/odsi/DOGL_Repo/DOGL/cleaning-tools/Table-cleaning/data'\n",
    "\n",
    "# Read the CSV\n",
    "partners_list_df = pd.read_csv(path+'/partner_data_raw.csv')\n",
    "\n",
    "# Duplicate the first column\n",
    "partners_list_df['cleaned'] = partners_list_df.iloc[:, 0]\n",
    "\n",
    "# Functions for quickly deleting and replacing one- or few-time errors\n",
    "def quick_remove(text):\n",
    "    partners_list_df['cleaned'] = partners_list_df['cleaned'].str.replace(text,'')\n",
    "    return partners_list_df\n",
    "\n",
    "def quick_replace(old_text, new_text):\n",
    "    partners_list_df['cleaned'] = partners_list_df['cleaned'].str.replace(old_text, new_text)\n",
    "    return partners_list_df\n",
    "\n",
    "# Solve all those little errors\n",
    "partners_list_df = quick_remove('\"')\n",
    "partners_list_df = quick_remove(\"Partnerships:' \")\n",
    "partners_list_df = quick_replace(\" 'Cooperations:'\",\";\")\n",
    "partners_list_df = quick_remove(\"Advisory Board: \")\n",
    "partners_list_df = quick_replace(\"Does not explictly state the name of these partners\", \"Not indicated\")\n",
    "partners_list_df = quick_replace(\"Includes a weblink to 'list of partners' that lists categories of Memberstates, Scientific Institutions, Civil Society, Business, Foundations. Only one partner is listed, Tara Ocean Foundation. https://ioc.unesco.org/partners IODE is the data collection/management entity/programme of IOC. See IODE for list of Partners.\",\"Tara Ocean Foundation\")\n",
    "partners_list_df = quick_remove(\"OCEAN DECADE PARTNERS: \")\n",
    "\n",
    "def comma_to_semicolon(row):\n",
    "    original_text = partners_list_df.loc[row, 'cleaned']\n",
    "    new_text = original_text.replace(',',';')\n",
    "    partners_list_df.loc[row, 'cleaned'] = new_text\n",
    "\n",
    "\n",
    "# On certain rows, replace commas with semicolons\n",
    "comma_rows = [31,34,40,41,42,43,44,45,46,51,57]\n",
    "for row in comma_rows:\n",
    "    comma_to_semicolon(row)\n",
    "\n",
    "# Replace NaN values with \"Not Indicated\"\n",
    "partners_list_df['cleaned'].fillna(\"Not Indicated\", inplace=True)\n",
    "\n",
    "# Display the cleaned data to check the results\n",
    "partners_list_df[['cleaned']].head()\n",
    "\n",
    "\n",
    "canonical_df = pd.read_csv(path+'/canonical_partners.csv',encoding='latin9')\n",
    "check_names = pd.DataFrame(columns=['Entry Name','Canonical Name','Score'])\n",
    "\n",
    "def find_canonical_name(org_name, threshold=95):\n",
    "    max_score = 0\n",
    "    canonical_name_to_return = org_name  # Default to original name\n",
    "    \n",
    "    for canonical_name in canonical_df['canonical_name']:\n",
    "        score = fuzz.token_set_ratio(org_name, canonical_name)\n",
    "        \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            canonical_name_to_return = canonical_name\n",
    "        \n",
    "        # Overwrite the name if similarity exceeds threshold\n",
    "        if max_score > threshold:\n",
    "            return canonical_name_to_return\n",
    "        \n",
    "        elif score > threshold - 5: # If the score is > 90, put it in the manual review dataframe\n",
    "            check_names.loc[len(check_names.index)] = [org_name, canonical_name, score]\n",
    "    \n",
    "    return org_name\n",
    "\n",
    "def process_canonical(org_names_str): # Processes the canonical naming convention on each row\n",
    "    org_names = org_names_str.split(';')\n",
    "    cleaned_names = [find_canonical_name(name.strip()) for name in org_names]\n",
    "    return '; '.join(cleaned_names)\n",
    "\n",
    "# Apply the function to your data\n",
    "partners_list_df['cleaned'] = partners_list_df['cleaned'].apply(process_canonical)\n",
    "\n",
    "\n",
    "#names_to_check = pd.DataFrame.from_records(check_names)\n",
    "#names_to_check.to_csv(path+'/names_to_check.csv')\n",
    "checked_names = pd.read_csv(path+'/checked_names.csv')\n",
    "\n",
    "for _, row in check_names.iterrows():\n",
    "    if row['Score'] == 1:\n",
    "        partners_list_df = quick_replace(row['Entry Name'], row['Canonical Name'])\n",
    "    \n",
    "\n",
    "# Replace some extraneous ones that didn't get solved on the first pass\n",
    "partners_list_df = quick_replace('United Nations Environment Program (UNEP)','United Nations Environment Programme (UNEP)')\n",
    "partners_list_df = quick_replace('National Oceanic and Atmospheric Administration, United States of America', 'National Oceanic & Atmospheric Administration (NOAA)')\n",
    "partners_list_df = quick_replace('National Aeronautic and Space Administration (NASA) Ames','National Aeronautics and Space Administration (NASA)')\n",
    "partners_list_df = quick_replace('US National Aeronautics and Space Administration (NASA)', 'National Aeronautics and Space Administration (NASA)')\n",
    "partners_list_df = quick_replace('International Council for Science (ICSU)', 'International Science Council (ISC)') # These two merged as the ISC\n",
    "partners_list_df = quick_replace('National Oceanographic & Atmospheric Administration (NOAA)','National Oceanographic and Atmospheric Administration (NOAA)')\n",
    "partners_list_df = quick_replace('None indicated', 'Not indicated')\n",
    "partners_list_df = quick_replace('World Wildlife Foundation (WWF)','World Wildlife Fund (WWF)')\n",
    "partners_list_df = quick_replace('International Oceanographic Commission (IOC)','Intergovernmental Oceanographic Commission (IOC)')\n",
    "\n",
    "# Test code by getting current matches after all cleaning\n",
    "def get_matches(df, col):\n",
    "    individual_orgs = df[col].str.split(';').explode().str.strip()\n",
    "    unique_orgs = individual_orgs.unique()\n",
    "    potential_matches = []\n",
    "\n",
    "    for org1, org2 in itertools.combinations(unique_orgs, 2): # Iterates through all unique pairs of org names\n",
    "        score = fuzz.token_set_ratio(org1, org2)\n",
    "        \n",
    "        # If similarity score is above 90 but not 100, store a potential match\n",
    "        if score > 90 and score < 100:\n",
    "            potential_matches.append((org1, org2, score))\n",
    "\n",
    "    # Creating a DataFrame for better visualization of potential matches\n",
    "    matches_df = pd.DataFrame(potential_matches, columns=['Org1', 'Org2', 'Score']).sort_values(by='Score', ascending=False)\n",
    "    return matches_df\n",
    "\n",
    "matches_df = get_matches(partners_list_df, 'cleaned')\n",
    "\n",
    "matches_df.to_csv(path+'/partner_matches.csv')\n",
    "\n",
    "\n",
    "partners_list_df.to_csv(path+'/partner_data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odsi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
